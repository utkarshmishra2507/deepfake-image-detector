{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. SETUP & CONFIGURATION\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Configuration\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10\n",
        "DATA_DIR = path\n",
        "\n",
        "print(f\" Device set to: {DEVICE}\")"
      ],
      "metadata": {
        "id": "beocyy-yq98N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. DATA PREPROCESSING & LOADING\n",
        "\n",
        "# using a pre-trained ResNet\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\" Loading Datasets...\")\n",
        "train_data = datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), transform=transform_train)\n",
        "test_data = datasets.ImageFolder(os.path.join(DATA_DIR, 'test'), transform=transform_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "class_names = train_data.classes\n",
        "print(f\" Data Loaded. Classes: {class_names}\")\n",
        "print(f\" Training Samples: {len(train_data)}\")\n",
        "print(f\" Testing Samples: {len(test_data)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "crvuQmpGrTlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. MODEL ARCHITECTURE\n",
        "\n",
        "def build_model():\n",
        "    \"\"\"\n",
        "    using ResNet18, a powerful feature extractor.\n",
        "    and replace the final layer to output just 2 classes: REAL vs FAKE.\n",
        "    \"\"\"\n",
        "    model = models.resnet18(pretrained=True)\n",
        "\n",
        "    # Freeze early layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Replace the final fully connected layer\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_ftrs, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(128, 2) # 2 Output Classes\n",
        "    )\n",
        "\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "model = build_model()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(\" Model Architecture Initialized (ResNet18 backbone)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Eov4gBfHs6Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. TRAINING LOOP\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accs.append(epoch_acc)\n",
        "\n",
        "        print(f\"Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "    return model, train_losses, train_accs\n",
        "\n",
        "print(\"ðŸš€ Starting Training Phase...\")\n",
        "trained_model, losses, accuracies = train_model(model, train_loader, criterion, optimizer, EPOCHS)\n",
        "\n"
      ],
      "metadata": {
        "id": "ROdH8AvJuDKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. EVALUATION & SAVING\n",
        "\n",
        "print(\"\\n Evaluating on Test Set...\")\n",
        "trained_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        outputs = trained_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "torch.save(trained_model.state_dict(), 'deepfake_detector_resnet.pth')\n",
        "print(\" Model saved as 'deepfake_detector_resnet.pth'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "B5vGgu9Ouwv0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}